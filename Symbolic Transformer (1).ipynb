{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78eca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14d3eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = check_random_state(0)\n",
    "boston = load_boston()\n",
    "perm = rng.permutation(boston.target.size)\n",
    "boston.data = boston.data[perm]\n",
    "boston.target = boston.target[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ad8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7593194530498841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "est = Ridge()\n",
    "est.fit(boston.data[:300, :], boston.target[:300])\n",
    "print(est.score(boston.data[300:, :], boston.target[300:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077d93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    11.04         0.339876        6         0.822502         0.675124     50.38s\n",
      "   1     6.91         0.593562        7         0.836993         0.602468     58.81s\n",
      "   2     5.07         0.730093        8          0.84063         0.704017     50.59s\n",
      "   3     5.22         0.735525        5         0.847019         0.628351     43.32s\n",
      "   4     6.24         0.734679       10         0.856612         0.565138      1.22m\n",
      "   5     8.23         0.721433       18          0.85677         0.728095     55.86s\n",
      "   6    10.20         0.717937       14         0.875233         0.619693      1.18m\n",
      "   7    11.84         0.720667       14         0.875927         0.609363     43.67s\n",
      "   8    12.56         0.733019       27         0.881705         0.390121      1.35m\n",
      "   9    13.61          0.73144       16         0.873285         0.598466      1.03m\n",
      "  10    14.81         0.737687       16         0.873915          0.67127     38.56s\n",
      "  11    14.84          0.73787       21         0.874944         0.467722     30.40s\n",
      "  12    15.40         0.740935       22         0.878053         0.534554     27.38s\n",
      "  13    16.83         0.743265       15         0.874735         0.635764     20.21s\n",
      "  14    17.04         0.741628       13         0.884417         0.493354     16.27s\n",
      "  15    17.02         0.744034       26         0.892236         0.647918     12.97s\n",
      "  16    18.23         0.738467       43         0.879153         0.377872     10.23s\n",
      "  17    18.09         0.722973       16         0.889763         0.508006      8.31s\n",
      "  18    19.58          0.70793       27         0.889402         0.639016      3.38s\n",
      "  19    21.69         0.697116       24         0.888272          0.56025      0.00s\n",
      "0.8418372105182026\n"
     ]
    }
   ],
   "source": [
    "function_set = ['add', 'sub', 'mul', 'div', 'sqrt', 'log',\n",
    "                'abs', 'neg', 'inv', 'max', 'min']\n",
    "gp = SymbolicTransformer(generations=20, population_size=2000,\n",
    "                         hall_of_fame=100, n_components=10,\n",
    "                         function_set=function_set,\n",
    "                         parsimony_coefficient=0.0005,\n",
    "                         max_samples=0.9, verbose=1,\n",
    "                         random_state=0)\n",
    "gp.fit(boston.data[:300, :], boston.target[:300])\n",
    "\n",
    "gp_features = gp.transform(boston.data)\n",
    "new_boston = np.hstack((boston.data, gp_features))\n",
    "\n",
    "est = Ridge()\n",
    "est.fit(new_boston[:300, :], boston.target[:300])\n",
    "print(est.score(new_boston[300:, :], boston.target[300:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8e6af",
   "metadata": {},
   "source": [
    "## Explain how the symbolic transformer method helps to improve the regressionâ€™s performance. \n",
    "What we can see is that when Ridge regression is done, we get a value of 0.7591. Making adjustments \n",
    "with the symbolic transformation considerably changes the value of R squared to 0.8417. from what \n",
    "can be inferred is that using the symbolic transformation helps to take advantage of some non-linear \n",
    "data and fits them better to the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
